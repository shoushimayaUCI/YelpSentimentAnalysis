{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('./train.csv', names=['class','text'])\n",
    "df_te = pd.read_csv('./test.csv', names=['class','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (560000, 2)\n",
      "test size: (38000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      1  Unfortunately, the frustration of being Dr. Go...\n",
       "1      2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2      1  I don't know what Dr. Goldberg was like before...\n",
       "3      1  I'm writing this review to give you a heads up...\n",
       "4      2  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training size:', df_tr.shape)\n",
    "print('test size:', df_te.shape)\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    280000\n",
       "2    280000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr['class'] = df_tr['class'] - 1\n",
    "df_te['class'] = df_te['class'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      0  Unfortunately, the frustration of being Dr. Go...\n",
       "1      1  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2      0  I don't know what Dr. Goldberg was like before...\n",
       "3      0  I'm writing this review to give you a heads up...\n",
       "4      1  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(11, 11))\n",
    "axs[0].hist([len(txt.split(' ')) for txt in df_tr['text'][df_tr['class'] == 0]])\n",
    "axs[0].set_title(\"negative texts\")\n",
    "axs[0].set_ylabel(\"word count\")\n",
    "axs[1].hist([len(txt.split(' ')) for txt in df_tr['text'][df_tr['class'] == 1]])\n",
    "axs[1].set_title(\"positive texts\")\n",
    "axs[1].set_ylabel(\"word count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class     int64\n",
       "text     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 6854, 1010, 1996, 9135, 1997, 2108, 2852, 1012, 18522, 1005, 1055, 5776, 2003, 1037, 9377, 1997, 1996, 3325, 1045, 1005, 2310, 2018, 2007, 2061, 2116, 2060, 7435, 1999, 16392, 1011, 1011, 2204, 3460, 1010, 6659, 3095, 1012, 2009, 3849, 2008, 2010, 3095, 3432, 2196, 6998, 1996, 3042, 1012, 2009, 2788, 3138, 1016, 2847, 1997, 5567, 4214, 2000, 2131, 2019, 3437, 1012, 2040, 2038, 2051, 2005, 2008, 2030, 4122, 2000, 3066, 2007, 2009, 1029, 1045, 2031, 2448, 2046, 2023, 3291, 2007, 2116, 2060, 7435, 1998, 1045, 2074, 2123, 1005, 1056, 2131, 2009, 1012, 2017, 2031, 2436, 3667, 1010, 2017, 2031, 5022, 2007, 2966, 3791, 1010, 2339, 3475, 1005, 1056, 3087, 10739, 1996, 3042, 1029, 2009, 1005, 1055, 4297, 25377, 2890, 10222, 19307, 1998, 2025, 2147, 1996, 12943, 17643, 21596, 1012, 2009, 1005, 1055, 2007, 9038, 2008, 1045, 2514, 2008, 1045, 2031, 2000, 2507, 2852, 1012, 18522, 1016, 3340, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\n",
    "    df_tr['text'][0],\n",
    "    padding='max_length',\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(data, maximum_length=None) :\n",
    "    input_ids = []\n",
    "    token_type_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            data[i],\n",
    "            padding='max_length',     #makes the short ones to max_length\n",
    "            truncation=True,    #makes the long lones to max_length\n",
    "            add_special_tokens=True,\n",
    "            max_length=maximum_length,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        token_type_ids.append(encoded['token_type_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "        \n",
    "    return np.asarray(input_ids), np.asarray(token_type_ids), np.asarray(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_tr, token_ids_tr, attention_masks_tr = bert_encode(df_tr['text'][:50000], 70)\n",
    "input_ids_te, token_ids_te, attention_masks_te = bert_encode(df_te['text'][:50000], 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bert_model):\n",
    "    input_ids = layers.Input(shape=(70,), dtype='int32')\n",
    "    token_ids = layers.Input(shape=(70,), dtype='int32')\n",
    "    attention_masks = layers.Input(shape=(70,), dtype='int32')\n",
    "    \n",
    "    output = bert_model([input_ids, token_ids, attention_masks])[1]  #pooled, sequence\n",
    "    \n",
    "    #clf_output = output[:, 0, :]\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(output)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    out = tf.keras.layers.Dense(1, activation='sigmoid')(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_ids, token_ids, attention_masks], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-dd66afb09fb7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-dd66afb09fb7>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    output = bert_model([input_ids=input_ids, token_type_ids=token_ids, attention_mask=attention_masks])\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def create_model2(bert_model):\n",
    "    input_ids = layers.Input(shape=(70,), dtype='int32')\n",
    "    token_ids = tf.keras.Input(shape=(70,), dtype='int32')\n",
    "    attention_masks = layers.Input(shape=(70,), dtype='int32')\n",
    "    \n",
    "    output = bert_model([input_ids=input_ids, token_type_ids=token_ids, attention_mask=attention_masks])\n",
    "    output = output[1]\n",
    "    \n",
    "    output = tf.keras.layers.Dense(32, activation='relu')(output)\n",
    "    output = tf.keras.layers.Dropout(0.2)(output)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n",
    "    model = tf.keras.models.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
    "    model.compile(Adam(lr=6e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_41 (InputLayer)           [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_11 (TFBertModel)  TFBaseModelOutputWit 109482240   input_40[0][0]                   \n",
      "                                                                 input_41[0][0]                   \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           24608       tf_bert_model_11[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_454 (Dropout)           (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            33          dropout_454[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 109,506,881\n",
      "Trainable params: 109,506,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel\n",
    "\n",
    "# module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "# bert_layer = hub.KerasLayer(module_url, trainable=True)\n",
    "\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "model = create_model(bert_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "13/13 [==============================] - 201s 16s/step - loss: 0.4375 - accuracy: 0.8225 - val_loss: 0.2995 - val_accuracy: 0.8600\n",
      "Epoch 2/4\n",
      "13/13 [==============================] - 183s 14s/step - loss: 0.2990 - accuracy: 0.8950 - val_loss: 0.3344 - val_accuracy: 0.8600\n",
      "Epoch 3/4\n",
      "13/13 [==============================] - 185s 14s/step - loss: 0.2370 - accuracy: 0.9175 - val_loss: 0.2753 - val_accuracy: 0.8800\n",
      "Epoch 4/4\n",
      "13/13 [==============================] - 183s 14s/step - loss: 0.1594 - accuracy: 0.9650 - val_loss: 0.2891 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236d12a26c8>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([input_ids_tr[1000:1500], token_ids_tr[1000:1500], attention_masks_tr[1000:1500]],\n",
    "          df_tr['class'][1000:1500], \n",
    "          validation_split = 0.2,\n",
    "          epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('saved_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x236835c8a88>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('saved_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2'\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/google/electra_small/2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "#     net = outputs['pooled_output']\n",
    "#     net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation='relu', name='classifier')(outputs)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer classifier expects 1 input(s), but it received 15 input tensors. Inputs received: [<tf.Tensor 'Placeholder:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'Placeholder_1:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_2:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_3:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_4:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_5:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_6:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_7:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_8:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_9:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_10:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_11:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_12:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_13:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'Placeholder_14:0' shape=(None, 128, 256) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f031ba765f1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_classifier_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-1e9e1be8b6cf>\u001b[0m in \u001b[0;36mbuild_classifier_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     net = outputs['pooled_output']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     net = tf.keras.layers.Dropout(0.1)(net)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 970\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[1;32m-> 1108\u001b[1;33m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    876\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2599\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[1;32m-> 2600\u001b[1;33m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[0;32m   2601\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2602\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    201\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                      \u001b[1;34m'but it received '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m                      ' input tensors. Inputs received: ' + str(inputs))\n\u001b[0m\u001b[0;32m    204\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer classifier expects 1 input(s), but it received 15 input tensors. Inputs received: [<tf.Tensor 'Placeholder:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'Placeholder_1:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_2:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_3:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_4:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_5:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_6:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_7:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_8:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_9:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_10:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_11:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_12:0' shape=(None, 128, 256) dtype=float32>, <tf.Tensor 'Placeholder_13:0' shape=(None, 256) dtype=float32>, <tf.Tensor 'Placeholder_14:0' shape=(None, 128, 256) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 232s 17s/step - loss: 8.4443 - accuracy: 0.4462 - val_loss: 6.9384 - val_accuracy: 0.5450\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 208s 16s/step - loss: 8.4443 - accuracy: 0.4462 - val_loss: 6.9384 - val_accuracy: 0.5450\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 205s 16s/step - loss: 8.4443 - accuracy: 0.4462 - val_loss: 6.9384 - val_accuracy: 0.5450\n",
      "Epoch 4/5\n",
      " 9/13 [===================>..........] - ETA: 1:04 - loss: 8.6571 - accuracy: 0.4323"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-34f0cffa5d64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     batch_size=64)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier_model.compile(\n",
    "    Adam(learning_rate=0.001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(\n",
    "    df_tr['text'][:1000], df_tr['class'][:1000],\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "?classifier_model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2888\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-94213955835b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sshim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 0)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
